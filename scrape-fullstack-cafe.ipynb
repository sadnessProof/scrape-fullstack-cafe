{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import bs4\n",
    "import time\n",
    "import json\n",
    "import shutil\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_by_xpath(browser, xpath):\n",
    "    \"\"\"\n",
    "    this method is waiting for xpath to load\n",
    "    :param browser:\n",
    "    :param xpath:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        WebDriverWait(browser, 30).until(EC.presence_of_element_located((By.XPATH, xpath)))\n",
    "    except TimeoutException:\n",
    "        print('failed wait_xpath')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_by_css_selector(browser, css_selector):\n",
    "    try:\n",
    "        WebDriverWait(browser, 30).until(EC.presence_of_element_located((By.CSS_SELECTOR, css_selector)))\n",
    "    except TimeoutException:\n",
    "        print('failed wait_css_selector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_by_class_name(browser, class_name):\n",
    "    try:\n",
    "        WebDriverWait(browser, 30).until(EC.presence_of_element_located((By.CLASS_NAME, class_name)))\n",
    "    except TimeoutException:\n",
    "        print('failed wait_class_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_directory(directory_address):\n",
    "    \"\"\"\n",
    "    this method cleans passed directory\n",
    "    :param directory_address:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    for file_name in os.listdir(directory_address):\n",
    "        file_path = os.path.join(directory_address, file_name)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "\n",
    "\n",
    "def setup_environment(dest_path):\n",
    "    if not os.path.exists(dest_path):\n",
    "        os.mkdir(dest_path)\n",
    "    else:\n",
    "        clear_directory(dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_question(q, is_challenge, a_json, q_json):\n",
    "    global question_enumeration\n",
    "    try:\n",
    "        if 'Mid' in q.text:\n",
    "            q_diff = 3\n",
    "        if 'Entry' in q.text:\n",
    "            q_diff = 1\n",
    "        if 'Junior' in q.text:\n",
    "            q_diff = 2\n",
    "        if 'Senior' in q.text:\n",
    "            q_diff = 4\n",
    "        if 'Expert' in q.text:\n",
    "            q_diff = 5\n",
    "\n",
    "        q.click()\n",
    "\n",
    "        q_json.append({\n",
    "            'id': question_enumeration,\n",
    "            'difficulty': q_diff,\n",
    "            'tittle': q.text,\n",
    "            'isChallenge': is_challenge\n",
    "        })\n",
    "\n",
    "\n",
    "        wait_by_css_selector(browser,answer_tag_css_selector)\n",
    "        a_content = browser.find_element_by_css_selector(answer_tag_css_selector).get_attribute('innerHTML')\n",
    "\n",
    "        a_json.append({\n",
    "            'id': question_enumeration,\n",
    "            'content': a_content,\n",
    "            'slug': q.text\n",
    "        })\n",
    "\n",
    "        question_enumeration += 1\n",
    "        q.click()\n",
    "    except:\n",
    "        print('failed on', question_enumeration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Edge(os.getcwd() + '\\\\' + 'msedgedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mccallisterkevin95@gmail.com\n",
    "# QoolKevin!245\n",
    "\n",
    "# get to the fullctack.cafe's home page\n",
    "browser.get('https://www.fullstack.cafe/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_folder = './Data'\n",
    "setup_environment(data_folder)\n",
    "\n",
    "# necessary variables\n",
    "topics_xpath = '//*[@id=\"root\"]/div/div[5]/div[2]/div/div/div/div'\n",
    "sections_xpath = '//*[@id=\"root\"]/div/div[5]/div[2]/div/div/nav[1]/div/div/div/button'\n",
    "topic_css_selector = 'div.p-2.topic-questions-spacer'\n",
    "question_css_selector = 'div.my-1.px-2.py-2.rounded.hovered'\n",
    "answer_tag_css_selector = 'div.d-block.px-2'\n",
    "question_tag_css_selector = 'div.col.justify-content-center.align-self-center.my-auto'\n",
    "question_enumeration = 1\n",
    "\n",
    "\n",
    "# get to the fullctack.cafe's home page\n",
    "browser.get('https://www.fullstack.cafe/')\n",
    "\n",
    "\n",
    "# get section elements (Full-Stack, Web & Mobile | System Design & Architecture | Coding & Data Structures) \n",
    "wait_by_xpath(browser, sections_xpath)\n",
    "SECTIONS = browser.find_elements_by_xpath(sections_xpath)\n",
    "\n",
    "root = browser.find_element_by_id(\"root\")\n",
    "\n",
    "# iterate them to scrape\n",
    "for section in SECTIONS:\n",
    "    browser.execute_script(\"arguments[0].scrollIntoView(true);\", root)\n",
    "    section.click()\n",
    "    section_folder = data_folder+'/'+section.text\n",
    "    os.mkdir(section_folder)\n",
    "    \n",
    "    # get topics for each section\n",
    "    wait_by_xpath(browser, topics_xpath)\n",
    "    TOPIC_CONTAINER = browser.find_elements_by_xpath(topics_xpath)\n",
    "    for topic in TOPIC_CONTAINER:\n",
    "        browser.execute_script(\"arguments[0].scrollIntoView(true);\", section)\n",
    "        topic.click()\n",
    "        topic_name = browser.current_url.split('/')[-1]\n",
    "        \n",
    "        answers_json = []\n",
    "        questions_json = []\n",
    "        \n",
    "        # get all of the question for each topic\n",
    "        wait_by_css_selector(browser, topic_css_selector)\n",
    "        topic_questions = browser.find_element_by_css_selector(topic_css_selector).find_elements_by_xpath('./div')\n",
    "        # iterate divs in the questions container\n",
    "        is_challenge = 0\n",
    "        for question in topic_questions:\n",
    "\n",
    "            if question.get_attribute('class') == 'my-2':\n",
    "                is_challenge += 1\n",
    "                pass\n",
    "\n",
    "            wait_by_css_selector(browser, question_css_selector)\n",
    "            q_tag = question.find_elements_by_css_selector(question_css_selector)\n",
    "            if len(q_tag):\n",
    "                try:\n",
    "                    scrape_question(question, is_challenge==2, answers_json, questions_json)\n",
    "                except:\n",
    "                    print(f'failed on: {question_enumeration}')\n",
    "       \n",
    "        with open(f'{section_folder}/{topic_name}-answers.json', 'w') as outfile:\n",
    "            json.dump(answers_json, outfile)\n",
    "        \n",
    "        with open(f'{section_folder}/{topic_name}-questions.json', 'w') as outfile:\n",
    "            json.dump(questions_json, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def section_topic_links(browser):\n",
    "    topic_links = []\n",
    "    wait_by_xpath(browser, topics_xpath)\n",
    "    for topic in browser.find_elements_by_xpath(topics_xpath):\n",
    "        topic_links.append(topic.find_element_by_xpath('./a[1]').get_attribute('href'))\n",
    "    \n",
    "    return topic_links\n",
    "\n",
    "        \n",
    "def get_section_elements(browser):\n",
    "    wait_by_xpath(browser, sections_xpath)\n",
    "    return browser.find_elements_by_xpath(sections_xpath)\n",
    "\n",
    "\n",
    "def scrape_question(browser, q, is_challenge, a_json, q_json):\n",
    "    global question_enumeration\n",
    "    if 'Mid' in q.text:\n",
    "        q_diff = 3\n",
    "    if 'Entry' in q.text:\n",
    "        q_diff = 1\n",
    "    if 'Junior' in q.text:\n",
    "        q_diff = 2\n",
    "    if 'Senior' in q.text:\n",
    "        q_diff = 4\n",
    "    if 'Expert' in q.text:\n",
    "        q_diff = 5\n",
    "\n",
    "    q.find_element_by_xpath('./div/div/div[1]/span').click()\n",
    "    q_text = q.find_element_by_xpath('./div/div/div[1]/h2').text\n",
    "\n",
    "    q_json.append({\n",
    "        'id': question_enumeration,\n",
    "        'difficulty': q_diff,\n",
    "        'title': q_text,\n",
    "        'isChallenge': is_challenge\n",
    "    })\n",
    "\n",
    "\n",
    "    wait_by_css_selector(browser,answer_tag_css_selector)\n",
    "    a_content = browser.find_element_by_css_selector(answer_tag_css_selector).get_attribute('innerHTML')\n",
    "\n",
    "    a_json.append({\n",
    "        'id': question_enumeration,\n",
    "        'content': a_content,\n",
    "        'slug': q_text\n",
    "    })\n",
    "\n",
    "    question_enumeration += 1\n",
    "    q.find_element_by_xpath('./div/div/div[1]/span').click()\n",
    "\n",
    "\n",
    "def scrape_section(browser, section_name, topic_links):\n",
    "    section_name = str(section_name).strip()\n",
    "    section_folder = data_folder+'/'+section_name\n",
    "    os.mkdir(section_folder)\n",
    "    # get all of the question for each topic\n",
    "    for link in topic_links:\n",
    "        browser.get(link)\n",
    "        topic_name = link.split('/')[-1]\n",
    "        \n",
    "        answers_json = []\n",
    "        questions_json = []\n",
    "\n",
    "        wait_by_css_selector(browser, topic_css_selector)\n",
    "        topic_questions = browser.find_element_by_css_selector(topic_css_selector).find_elements_by_xpath('./div')\n",
    "        \n",
    "        is_challenge = 0\n",
    "        for question in topic_questions:\n",
    "\n",
    "            if question.get_attribute('class') == 'my-2':\n",
    "                is_challenge += 1\n",
    "                pass\n",
    "\n",
    "            wait_by_css_selector(browser, question_css_selector)\n",
    "            if len(question.find_elements_by_css_selector(question_css_selector)):\n",
    "                scrape_question(browser, question, is_challenge==2, answers_json, questions_json)\n",
    "            \n",
    "        with open(f'{section_folder}/{topic_name}-answers.json', 'w') as outfile:\n",
    "            json.dump(answers_json, outfile)\n",
    "        \n",
    "        with open(f'{section_folder}/{topic_name}-questions.json', 'w') as outfile:\n",
    "            json.dump(questions_json, outfile)\n",
    "\n",
    "\n",
    "def scrape_the_site(browser):\n",
    "    section_names = []\n",
    "    topic_links = []\n",
    "    \n",
    "    for section in get_section_elements(browser):\n",
    "        section.click()\n",
    "        section_names.append(section.text)\n",
    "        topic_links.append(section_topic_links(browser))\n",
    "        \n",
    "    \n",
    "    for i in range(0, len(section_names)):\n",
    "        scrape_section(browser, section_names[i], topic_links[i])\n",
    "        \n",
    "    \n",
    "def main():\n",
    "    setup_environment(data_folder)\n",
    "    # get to the fullctack.cafe's home page\n",
    "    browser.get('https://www.fullstack.cafe/')\n",
    "    scrape_the_site(browser)\n",
    "    browser.quit()\n",
    "\n",
    "\n",
    "# necessary variables\n",
    "topics_xpath = '//*[@id=\"root\"]/div/div[5]/div[2]/div/div/div/div'\n",
    "sections_xpath = '//*[@id=\"root\"]/div/div[5]/div[2]/div/div/nav[1]/div/div/div/button'\n",
    "topic_css_selector = 'div.p-2.topic-questions-spacer'\n",
    "question_css_selector = 'div.my-1.px-2.py-2.rounded.hovered'\n",
    "answer_tag_css_selector = 'div.d-block.px-2'\n",
    "question_tag_css_selector = 'div.col.justify-content-center.align-self-center.my-auto'\n",
    "question_enumeration = 1\n",
    "data_folder = './Data'\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
